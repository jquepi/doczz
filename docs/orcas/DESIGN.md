# 存储层设计

## 原则和默认约定

1. 元数据和数据分开存储

- 提供存储适配器，这样你可以随意修改成你想要的实现

2. 按对象大小分类存储（better to have）

- 小对象支持打包存储，多个小文件打包成一个数据上传
- 大对象存储分块存储，数据块默认按4MB切块，也即4194304B，读取大对象时，根据数据总大小计算出需要读取多少个块即可，理论上支持无限大的对象存储（前端因为受到浏览器自带的上传下载功能限制，支持大小受限）

3. 只追加（WORM， Write-Once-Read-Many）模式，数据只追加不修改

- 这可以简化强一致问题，不再需要引入NRW quorum算法等，不再需要读取多个副本选择更新版本，只需要读取元数据中的最新版本即可，这样也就不需要使用Raft或者Paxos来解决多副本数据同步问题，自增主键作为协议号，修改时间戳作为版本即可，修改时间戳需要保证时间不回跳

4. 数据引用/秒传（对象级重复数据删除）

- 在本来就要提供校验值来满足完整性校验的同时，还能够支持对象级重复数据删除
- 秒传的数据引用功能还能够用于云端复制和剪切功能，只需要提供索引（目录信息）即可
- OrcaS与其他对象存储设计不同，从一开始就支持，数据独立于元数据，而非依附于元数据存在而存在（后续实现秒传会比较复杂）

5. 支持常见压缩方法

- snappy、zstd、gzip等

6. 支持加密方法（数据私有安全，常见的国密SM4、国际AES-256）

- 拥有正确密钥的设备才能在设备端访问数据（全链路）

## 关于存储选型

- 数据部分为什么用自研存储而不是RocksDB，因为LSM类的实现存在写放大问题
- 元数据部分用关系型数据库存储因为查询和排序比较方便，也可以改用合适的KV存储，后续可以看场景和性能测试而定

## 元数据设计

- 一般元数据存储会设计成全路径或者父子对象id的方式

<table style="text-align: center">
   <tr>
      <td>方案</td>
      <td>优点</td>
      <td>缺点</td>
   </tr>
   <tr>
      <td>全路径</td>
      <td>前缀查询，定位较快<br/></td>
      <td>移动/重命名需要批量修改前缀</td>
   </tr>
   <tr>
      <td>父子id</td>
      <td>移动可以配合引用功能</td>
      <td>需要每一级查询（可以通过给父id解决）
      ；客户端需要维护id和名称的关系</td>
   </tr>
</table>

这里我们选择的是父子id方案

## 接口设计

- 批量写入对象信息，同时可以带部分对象的秒传/秒传预筛选
- 读取对象信息
- 列举对象信息：无限加载模式，支持按对象名、对象类型过滤，支持对象名称、大小、时间排序
- 随机读取数据的一部分（在线播放和在线预览等）
- id生成器，默认单机的，如果是分布式的，可能需要通过配置支持

### 【对象的属性】

- 父级的id
- 对象名称
- 对象大小
- 创建时间
- 修改时间（如果没有，那就是创建时间）
- 访问时间（如果没有，那就是修改时间>创建时间）
- 对象的类型
- 数据id
- 幂等操作id
- 快照版本

### 【数据的属性】

- 是否压缩
- 是否加密
- 原始MD5值
- 原始CRC32值
- 前32KB头部CRC32值
- 8KB对齐，最大尽量在4MB以内
- 打包块的ID和偏移位置

## 端到端的实现

- 在客户端做加解密和解压缩
- 本地的实现，数据直接写入存储；远端的实现，数据通过rpc传输，调用方无法感觉到差别

### 上传对象的过程

1. hdrCRC32和长度来预检查是否可能秒传（可以用阈值来优化小对象直接跳过预检查）
2. 没有可能的直接上传
3. 有可能的，计算整个对象的MD5和CRC32后尝试秒传
4. 秒传失败，转普通上传
### 秒传的实现逻辑

- 如果两个数据的哈希值和长度完全相同，那我们认为他们是完全等同的，那么对象可以使用相同的数据信息，为了防止删除过程中可能被同时删除的问题，我们引入一个相对较长的时间窗口即可