# 设计方案

## 领域模型

主要分为用户、存储两部分，它们之间的关联是访问和权限控制

- 用户分为管理员和普通用户

- 存储按类别分为元数据和数据

   - 元数据有桶信息、对象信息、数据信息，桶里面用有对象，每个对象信息可以关联数据信息，比如版本和预览的数据等，也可以不关联数据，比如目录和文件对象

![architecture](https://orcastor.github.io/doc//assets/img/arch.png)

## 存储设计

### 关于存储选型

数据部分为什么用自研存储而不是RocksDB？因为LSM类的实现存在写放大问题严重。元数据部分用关系型数据库存储因为查询和排序比较方便，也可以改用合适的KV存储，后续可以看场景和性能测试而定

### 原则和默认约定

1. 元数据和数据分开存储

提供存储适配器，这样你可以随意修改成你想要的实现。

2. 按对象大小分类存储

小对象支持打包存储，多个小文件打包成一个数据包上传；大对象存储分块存储，数据块默认按4MB切块，也即4194304B，读取大对象时，根据数据总大小计算出需要读取多少个块即可，理论上支持无限大的对象存储（前端因为受到浏览器自带的上传下载功能限制，支持大小受限）。

3. 数据只追加不修改（WORM， Write-Once-Read-Many）

这可以简化强一致问题，不再需要引入NRW quorum算法等，不再需要读取多个副本选择更新版本，只需要读取元数据中的最新版本即可，这样也就不需要使用Raft或者Paxos来解决多副本数据同步问题，单调递增的ID作为协议号，修改时间戳作为版本即可，修改时间戳需要保证时间不回跳。

4. 数据引用/秒传（对象级重复数据删除）

校验值满足完整性校验本身就需要提供，现在还能额外支持对象级重复数据删除，秒传的数据引用功能还能够用于云端复制和剪切功能，只需要提供索引（目录信息）即可。**`OrcaS`从一开始就支持秒传，数据独立于元数据，而非依附于元数据存在而存在（否则后续实现会相对比较复杂）**。

5. 支持常见压缩方法

支持snappy、zstd、gzip等。

6. 支持常见加密方法

保障数据私有安全，支持国密SM4、AES-256等，拥有正确密钥的设备才能在设备端访问数据（全链路）。

## 元数据设计

- 一般元数据存储会设计成全路径或者父子对象id的方式

<table style="text-align: center">
   <tr>
      <td>方案</td>
      <td>优点</td>
      <td>缺点</td>
   </tr>
   <tr>
      <td>全路径</td>
      <td>前缀查询，定位较快<br/></td>
      <td>移动/重命名需要批量修改前缀，层级深的话，占用空间比较多</td>
   </tr>
   <tr>
      <td>父子id</td>
      <td>移动可以配合秒传/数据引用功能</td>
      <td>需要每一级查询（可以通过给父id解决）
      ；客户端需要维护id和名称的关系</td>
   </tr>
</table>

这里我们选择的是父子id方案。

## 数据设计

数据存储方式和ceph、Swift以及常见对象存储设计类似，用对象的名称做hash，第一级为hash十六进制字符串的最后三个字母，第二级为hash值，第三级为对象名称。

## ID生成方案设计

并没有使用数据库主键的方式，这有几个方面的考量，一个是后续扩展为多节点时，用额外的id生成器便于服务迁移和无缝切换为集群版本。
参考MongoDB的对象ID的设计，前半部分是时间戳，后面是实例号和序号，正好和snowflake雪花❄️算法也接近。

## 接口设计

- 批量写入对象信息，同时可以带部分对象的秒传/秒传预筛选
- 读取对象信息
- 列举对象信息：无限加载模式，支持按对象名、对象类型过滤，支持对象名称、大小、时间排序
- 随机读取数据的一部分（在线播放和在线预览等）
- ID生成器，默认单机的，如果是分布式的，可能需要通过配置支持

### 【对象的属性】

- 父级的ID
- 对象名称
- 对象大小
- 创建时间
- 修改时间（如果没有，那就是创建时间）
- 访问时间（如果没有，那就是修改时间>创建时间）
- 对象的类型
- 数据ID
- 幂等操作ID
- 快照版本ID

``` go
type ObjectInfo struct {
	ID     int64  `borm:"id"`     // 对象ID（idgen随机生成的id）
	PID    int64  `borm:"pid"`    // 父对象ID
	MTime  int64  `borm:"mtime"`  // 更新时间，秒级时间戳
	DataID int64  `borm:"did"`    // 数据ID，如果为0，说明没有数据（新创建的文件，DataID就是对象ID，作为对象的首版本数据）
	Type   int    `borm:"type"`   // 对象类型，0: none, 1: dir, 2: file, 3: version, 4: preview(thumb/m3u8/pdf)
	Status int    `borm:"status"` // 对象状态，0: none, 1: normal, 1: deleted, 2: recycle(to be deleted), 3: malformed
	Name   string `borm:"name"`   // 对象名称
	Size   int64  `borm:"size"`   // 对象的大小，目录的大小是子对象数，文件的大小是最新版本的字节数
	Ext    string `borm:"ext"`    // 对象的扩展信息
}
```

### 【数据的属性】

- 是否压缩
- 是否加密
- 原始MD5值
- 原始CRC32值
- 前100KB头部CRC32值
- 8KB对齐，最大尽量在4MB以内
- 打包块的ID和偏移位置

``` go
type DataInfo struct {
	ID       int64  `borm:"id"`        // 数据ID（idgen随机生成的id）
	Size     int64  `borm:"size"`      // 数据的大小
	OrigSize int64  `borm:"o_size"`    // 数据的原始大小
	HdrCRC32 uint32 `borm:"hdr_crc32"` // 头部100KB的CRC32校验值
	CRC32    uint32 `borm:"crc32"`     // 整个数据的CRC32校验值（最原始数据）
	MD5      string `borm:"md5"`       // 整个数据的MD5值（最原始数据）

	Checksum uint32 `borm:"checksum"` // 整个数据的CRC32校验值（最终数据，用于一致性审计）
	Kind     uint32 `borm:"kind"`     // 数据状态，正常、损坏、加密、压缩、类型（用于预览等）

	// PkgID不为0说明是打包数据
	PkgID     int64 `borm:"pkg_id"`  // 打包数据的ID（也是idgen生成的id）
	PkgOffset int   `borm:"pkg_off"` // 打包数据的偏移位置
}
```

## 重要逻辑

在客户端实现打包和组装、加解密和解压缩逻辑。本地的实现，数据直接写入存储；远端的实现，数据通过rpc传输，调用方无法感觉到差别。

### 上传对象的过程

1. hdrCRC32和长度来预检查是否可能秒传（可以用阈值来优化小对象直接跳过预检查）
2. 没有可能的直接上传
3. 有可能的，计算整个对象的MD5和CRC32后尝试秒传
4. 秒传失败，转普通上传

### 秒传的实现逻辑

如果两个数据的哈希值和长度完全相同，那我们认为他们是完全等同的，那么对象可以使用相同的数据信息（同样的数据ID），为了防止引用过程中可能被同时删除的问题，我们引入一个相对较长的时间窗口即可，需要同时提供MD5和CRC32，是因为存在哈希冲突和漏洞问题。

